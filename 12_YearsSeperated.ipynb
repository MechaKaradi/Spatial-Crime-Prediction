{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Develop the crime data\n",
    "\n",
    "This notebook will create the base grid used to train and test the crime prediction model. \n",
    "The grid will be created on a 150m x 150m grid, within the bounds of the police precincts polygon.\n",
    "\n",
    "For each grid cell, the number of crimes will be calculated, disaggregated by the characteristics of the victim. The crimes affecting the following groups will be counted:\n",
    "- All Male and Female victims\n",
    "- Male victims\n",
    "- Female victims"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import the required libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import the police precincts shapefile\n",
    "Only points within the jurisdiction of the precincts will be considered in the analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "precint_footprint = gpd.read_file('..//data//Police Precincts.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create the base grid for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid of points across the precincts to use as the center of the crime clusters\n",
    "# The size of the grid is n x n, where n is the number of points in each direction\n",
    "from shapely.geometry import Point, Polygon\n",
    "from rtree import index\n",
    "# get the bounds of the precincts\n",
    "min_x, min_y, max_x, max_y = precint_footprint.total_bounds\n",
    "\n",
    "idx = index.Index()\n",
    "for i, row in precint_footprint.iterrows():\n",
    "    idx.insert(i, row.geometry.bounds)\n",
    "\n",
    "grid_size = 100  # You can adjust this value\n",
    "x_points = np.linspace(min_x, max_x, grid_size)\n",
    "y_points = np.linspace(min_y, max_y, grid_size)\n",
    "\n",
    "# Round the points to 4 decimal places\n",
    "x_points = np.around(x_points, 4)\n",
    "y_points = np.around(y_points, 4)\n",
    "\n",
    "grid = [Point(x, y) for x in x_points for y in y_points]\n",
    "\n",
    "# drop the points that are not within the precincts\n",
    "def is_point_inside_precincts(point, precincts_gdf, idx):\n",
    "    for i in idx.intersection(point.bounds):\n",
    "        if point.within(precincts_gdf.iloc[i].geometry):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "filtered_grid = [point for point in grid if is_point_inside_precincts(point, precint_footprint, idx)]\n",
    "filtered_grid_df = pd.DataFrame([(point.x, point.y) for point in filtered_grid], columns=['Longitude', 'Latitude'])\n",
    "\n",
    "del grid \n",
    "del filtered_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate the basic spatial-temporal matrix\n",
    "For each point, crime probabbility will be analysed for each hour of the day and each day of the week."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def point_hour_day_combinations(points, hours, days_of_week):\n",
    "    for point, hour, day in itertools.product(points, hours, days_of_week):\n",
    "        yield point.x, point.y, hour, day\n",
    "\n",
    "# Convert filtered grid points to a list of Point objects\n",
    "points = [Point(lon, lat) for lon, lat in filtered_grid_df[['Longitude', 'Latitude']].values]\n",
    "\n",
    "# Define hours and days_of_week\n",
    "hours = range(24)\n",
    "days_of_week = range(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import the crime data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "with open('..//data.pickle', 'rb') as f:\n",
    "    crime_data = pd.read_pickle(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    CMPLNT_NUM CMPLNT_FR_DT CMPLNT_FR_TM CMPLNT_TO_DT CMPLNT_TO_TM   \n0    506547392   03/29/2018     20:30:00         <NA>          NaN  \\\n3    280364018   06/09/2018     21:42:00   06/09/2018     21:43:00   \n8    570490441   01/16/2018     14:30:00   01/16/2018     15:00:00   \n9    377132404   08/04/2018     22:15:00         <NA>          NaN   \n10   504303130   09/26/2018     18:20:00   09/26/2018     18:24:00   \n\n   ADDR_PCT_CD     RPT_DT KY_CD                       OFNS_DESC  PD_CD  ...   \n0         32.0 2018-03-30   351  CRIMINAL MISCHIEF & RELATED OF  254.0  ...  \\\n3         10.0 2018-06-10   361   OFF. AGNST PUB ORD SENSBLTY &  639.0  ...   \n8         69.0 2018-01-16   344    ASSAULT 3 & RELATED OFFENSES  101.0  ...   \n9         44.0 2018-08-04   344    ASSAULT 3 & RELATED OFFENSES  101.0  ...   \n10        28.0 2018-09-26   106                  FELONY ASSAULT  109.0  ...   \n\n     Latitude  Longitude                        Lat_Lon   \n0   40.810877 -73.941064  (40.810877241, -73.941064151)  \\\n3   40.759310 -73.994706  (40.759310399, -73.994706072)   \n8   40.635516 -73.913278  (40.635516265, -73.913277993)   \n9   40.826170 -73.916831  (40.826169612, -73.916830709)   \n10  40.803905 -73.952037  (40.803905237, -73.952036608)   \n\n                PATROL_BORO STATION_NAME VIC_AGE_GROUP        VIC_RACE   \n0     PATROL BORO MAN NORTH          NaN           NaN           WHITE  \\\n3     PATROL BORO MAN SOUTH          NaN         25-44  WHITE HISPANIC   \n8   PATROL BORO BKLYN SOUTH          NaN           NaN           BLACK   \n9         PATROL BORO BRONX          NaN         45-64  WHITE HISPANIC   \n10    PATROL BORO MAN NORTH          NaN         25-44           BLACK   \n\n   VIC_SEX        OCC     OCC_END  \n0        F 2018-03-29        <NA>  \n3        F 2018-06-09  06/09/2018  \n8        M 2018-01-16  01/16/2018  \n9        F 2018-08-04        <NA>  \n10       M 2018-09-26  09/26/2018  \n\n[5 rows x 37 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CMPLNT_NUM</th>\n      <th>CMPLNT_FR_DT</th>\n      <th>CMPLNT_FR_TM</th>\n      <th>CMPLNT_TO_DT</th>\n      <th>CMPLNT_TO_TM</th>\n      <th>ADDR_PCT_CD</th>\n      <th>RPT_DT</th>\n      <th>KY_CD</th>\n      <th>OFNS_DESC</th>\n      <th>PD_CD</th>\n      <th>...</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Lat_Lon</th>\n      <th>PATROL_BORO</th>\n      <th>STATION_NAME</th>\n      <th>VIC_AGE_GROUP</th>\n      <th>VIC_RACE</th>\n      <th>VIC_SEX</th>\n      <th>OCC</th>\n      <th>OCC_END</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>506547392</td>\n      <td>03/29/2018</td>\n      <td>20:30:00</td>\n      <td>&lt;NA&gt;</td>\n      <td>NaN</td>\n      <td>32.0</td>\n      <td>2018-03-30</td>\n      <td>351</td>\n      <td>CRIMINAL MISCHIEF &amp; RELATED OF</td>\n      <td>254.0</td>\n      <td>...</td>\n      <td>40.810877</td>\n      <td>-73.941064</td>\n      <td>(40.810877241, -73.941064151)</td>\n      <td>PATROL BORO MAN NORTH</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>WHITE</td>\n      <td>F</td>\n      <td>2018-03-29</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>280364018</td>\n      <td>06/09/2018</td>\n      <td>21:42:00</td>\n      <td>06/09/2018</td>\n      <td>21:43:00</td>\n      <td>10.0</td>\n      <td>2018-06-10</td>\n      <td>361</td>\n      <td>OFF. AGNST PUB ORD SENSBLTY &amp;</td>\n      <td>639.0</td>\n      <td>...</td>\n      <td>40.759310</td>\n      <td>-73.994706</td>\n      <td>(40.759310399, -73.994706072)</td>\n      <td>PATROL BORO MAN SOUTH</td>\n      <td>NaN</td>\n      <td>25-44</td>\n      <td>WHITE HISPANIC</td>\n      <td>F</td>\n      <td>2018-06-09</td>\n      <td>06/09/2018</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>570490441</td>\n      <td>01/16/2018</td>\n      <td>14:30:00</td>\n      <td>01/16/2018</td>\n      <td>15:00:00</td>\n      <td>69.0</td>\n      <td>2018-01-16</td>\n      <td>344</td>\n      <td>ASSAULT 3 &amp; RELATED OFFENSES</td>\n      <td>101.0</td>\n      <td>...</td>\n      <td>40.635516</td>\n      <td>-73.913278</td>\n      <td>(40.635516265, -73.913277993)</td>\n      <td>PATROL BORO BKLYN SOUTH</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>BLACK</td>\n      <td>M</td>\n      <td>2018-01-16</td>\n      <td>01/16/2018</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>377132404</td>\n      <td>08/04/2018</td>\n      <td>22:15:00</td>\n      <td>&lt;NA&gt;</td>\n      <td>NaN</td>\n      <td>44.0</td>\n      <td>2018-08-04</td>\n      <td>344</td>\n      <td>ASSAULT 3 &amp; RELATED OFFENSES</td>\n      <td>101.0</td>\n      <td>...</td>\n      <td>40.826170</td>\n      <td>-73.916831</td>\n      <td>(40.826169612, -73.916830709)</td>\n      <td>PATROL BORO BRONX</td>\n      <td>NaN</td>\n      <td>45-64</td>\n      <td>WHITE HISPANIC</td>\n      <td>F</td>\n      <td>2018-08-04</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>504303130</td>\n      <td>09/26/2018</td>\n      <td>18:20:00</td>\n      <td>09/26/2018</td>\n      <td>18:24:00</td>\n      <td>28.0</td>\n      <td>2018-09-26</td>\n      <td>106</td>\n      <td>FELONY ASSAULT</td>\n      <td>109.0</td>\n      <td>...</td>\n      <td>40.803905</td>\n      <td>-73.952037</td>\n      <td>(40.803905237, -73.952036608)</td>\n      <td>PATROL BORO MAN NORTH</td>\n      <td>NaN</td>\n      <td>25-44</td>\n      <td>BLACK</td>\n      <td>M</td>\n      <td>2018-09-26</td>\n      <td>09/26/2018</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 37 columns</p>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only keep the M and F sex values\n",
    "sexes = ['M', 'F']\n",
    "\n",
    "crime_data = crime_data.loc[crime_data['VIC_SEX'].isin(sexes)]\n",
    "# Re calculate the categories for the Sex column\n",
    "crime_data['VIC_SEX'] = crime_data['VIC_SEX'].cat.remove_unused_categories()\n",
    "\n",
    "del sexes\n",
    "crime_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter crime_data columns to only include the columns we need\n",
    "crime_data = crime_data[['CMPLNT_FR_DT', 'CMPLNT_FR_TM', 'Longitude','Latitude', 'VIC_SEX','VIC_AGE_GROUP']]\n",
    "crime_data.head(5)\n",
    "\n",
    "# get the day of the week and the hour of the day from the date and time columns\n",
    "crime_data['CMPLNT_FR_DT'] = pd.to_datetime(crime_data['CMPLNT_FR_DT'], format='%m/%d/%Y')\n",
    "crime_data['CMPLNT_FR_TM'] = pd.to_datetime(crime_data['CMPLNT_FR_TM'], format='%H:%M:%S')\n",
    "crime_data['day_of_week'] = crime_data['CMPLNT_FR_DT'].dt.dayofweek\n",
    "crime_data['hour'] = crime_data['CMPLNT_FR_TM'].dt.hour\n",
    "crime_data['year'] = crime_data['CMPLNT_FR_DT'].dt.year\n",
    "# convert the year to an integer\n",
    "crime_data['year'] = crime_data['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nearest_grid_point(coord, grid_points):\n",
    "    nearest_index = np.argmin(np.abs(coord - grid_points))\n",
    "    return grid_points[nearest_index]\n",
    "\n",
    "# Find the nearest grid point for the longitude and latitude coordinates using the defined function\n",
    "crime_data['Longitude'] = crime_data['Longitude'].apply(nearest_grid_point, grid_points=x_points)\n",
    "crime_data['Latitude'] = crime_data['Latitude'].apply(nearest_grid_point, grid_points=y_points)\n",
    "\n",
    "\n",
    "crime_counts = (\n",
    "    crime_data.groupby(['Longitude', 'Latitude', 'day_of_week', 'hour', 'year', 'VIC_SEX'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "   Longitude  Latitude  day_of_week  hour  year VIC_SEX  count\n0   -74.2556   40.4961            0   0.0  2006       F     30\n1   -74.2556   40.4961            0   0.0  2006       M     26\n2   -74.2556   40.4961            0   0.0  2007       F      0\n3   -74.2556   40.4961            0   0.0  2007       M      3\n4   -74.2556   40.4961            0   0.0  2008       F      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Longitude</th>\n      <th>Latitude</th>\n      <th>day_of_week</th>\n      <th>hour</th>\n      <th>year</th>\n      <th>VIC_SEX</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-74.2556</td>\n      <td>40.4961</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2006</td>\n      <td>F</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-74.2556</td>\n      <td>40.4961</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2006</td>\n      <td>M</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-74.2556</td>\n      <td>40.4961</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2007</td>\n      <td>F</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-74.2556</td>\n      <td>40.4961</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2007</td>\n      <td>M</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-74.2556</td>\n      <td>40.4961</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2008</td>\n      <td>F</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crime_counts.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crime_datasets = dict()\n",
    "\n",
    "crime_datasets['crime_counts_rest'] = (\n",
    "    crime_data.loc[crime_data['year'] == 2021]\n",
    "    .groupby(['Longitude', 'Latitude', 'day_of_week', 'hour', 'VIC_SEX'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    "    )\n",
    "\n",
    "crime_datasets['crime_counts_2021'] = (\n",
    "    crime_data.loc[crime_data['year'] != 2021]\n",
    "    .groupby(['Longitude', 'Latitude', 'day_of_week', 'hour', 'VIC_SEX'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    ")\n",
    "\n",
    "# add the data frames to a list\n",
    "\n",
    "# remove the year column from the data frames\n",
    "for crime_counts in crime_datasets.values():\n",
    "    del crime_counts['year']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for crime_counts in crime_datasets.values():\n",
    "    crime_counts = pd.pivot_table(crime_counts, values='count', index=['Longitude', 'Latitude','hour', 'day_of_week'], columns=['VIC_SEX'], fill_value=0)\n",
    "    crime_counts = crime_counts.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trees"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Count the trees close to each grid point\n",
    "rows = None\n",
    "\n",
    "trees = gpd.read_file('../data/2015 Street Tree Census - Tree Data.geojson', rows=rows)\n",
    "trees = trees.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "trees['longitude'] = trees['longitude'].astype(float)\n",
    "trees['latitude'] = trees['latitude'].astype(float)\n",
    "\n",
    "trees['Longitude'] = trees['longitude'].apply(nearest_grid_point, grid_points=x_points)\n",
    "trees['Latitude'] = trees['latitude'].apply(nearest_grid_point, grid_points=y_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "trees.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tree_counts = (\n",
    "    trees.groupby(['Longitude', 'Latitude','health'])\n",
    "    .size()\n",
    "    .reset_index(name='tree_count')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tree_counts.head()\n",
    "\n",
    "tree_counts_pivoted = pd.pivot_table(tree_counts, values='tree_count', index=['Longitude', 'Latitude'], columns=['health'], fill_value=0)\n",
    "tree_counts_pivoted = tree_counts_pivoted.reset_index().rename(columns={'Good': 'good_tree_count', 'Fair': 'fair_tree_count', 'Poor': 'poor_tree_count'})\n",
    "\n",
    "# Remove index name\n",
    "tree_counts_pivoted.index.name = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "all_combinations = np.array(list(point_hour_day_combinations(points, hours, days_of_week)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Use the reindex method to index the matches directly\n",
    "for crime_counts in crime_datasets.values():\n",
    "    crime_counts.set_index(['Longitude', 'Latitude', 'hour', 'day_of_week'], inplace=True)\n",
    "    crime_counts = crime_counts.reindex(\n",
    "        pd.MultiIndex.from_arrays(all_combinations.T,\n",
    "        names=crime_counts.index.names),\n",
    "        fill_value=0\n",
    "        )\n",
    "    # Reset the index of the matched_data DataFrame\n",
    "    crime_counts.reset_index(inplace=True)\n",
    "    # Add the tree counts to the matched_df DataFrame\n",
    "    crime_counts = crime_counts.merge(tree_counts_pivoted, on=['Longitude', 'Latitude'], how='left').fillna(0)\n",
    "    crime_counts[['hour', 'day_of_week']] = crime_counts[['hour', 'day_of_week']].astype(int)\n",
    "    #Convert the tree count columns to int type\n",
    "    crime_counts[['good_tree_count', 'fair_tree_count', 'poor_tree_count']] = crime_counts[['good_tree_count', 'fair_tree_count', 'poor_tree_count']].astype(int)\n",
    "    # convert the F and M columns to int type\n",
    "    crime_counts[['F', 'M']] = crime_counts[['F', 'M']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute '__name__'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[33], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mcrime_counts_rest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\geo_env\\lib\\site-packages\\pandas\\core\\generic.py:5989\u001B[0m, in \u001B[0;36mNDFrame.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   5982\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   5983\u001B[0m     name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_names_set\n\u001B[0;32m   5984\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_metadata\n\u001B[0;32m   5985\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accessors\n\u001B[0;32m   5986\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info_axis\u001B[38;5;241m.\u001B[39m_can_hold_identifiers_and_holds_name(name)\n\u001B[0;32m   5987\u001B[0m ):\n\u001B[0;32m   5988\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m[name]\n\u001B[1;32m-> 5989\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mobject\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getattribute__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute '__name__'"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Final Export"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the matched_data DataFrame as a parquet file\n",
    "for key in crime_datasets.keys():\n",
    "    crime_datasets[key].to_parquet(f'../data/{key}.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
