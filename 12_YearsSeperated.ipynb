{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Develop the crime data\n",
    "\n",
    "This notebook will create the base grid used to train and test the crime prediction model. \n",
    "The grid will be created on a 150m x 150m grid, within the bounds of the police precincts polygon.\n",
    "\n",
    "For each grid cell, the number of crimes will be calculated, disaggregated by the characteristics of the victim. The crimes affecting the following groups will be counted:\n",
    "- All Male and Female victims\n",
    "- Male victims\n",
    "- Female victims"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import the required libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import the police precincts shapefile\n",
    "Only points within the jurisdiction of the precincts will be considered in the analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "precint_footprint = gpd.read_file('..//data//Police Precincts.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create the base grid for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid of points across the precincts to use as the center of the crime clusters\n",
    "# The size of the grid is n x n, where n is the number of points in each direction\n",
    "from shapely.geometry import Point, Polygon\n",
    "from rtree import index\n",
    "# get the bounds of the precincts\n",
    "min_x, min_y, max_x, max_y = precint_footprint.total_bounds\n",
    "\n",
    "idx = index.Index()\n",
    "for i, row in precint_footprint.iterrows():\n",
    "    idx.insert(i, row.geometry.bounds)\n",
    "\n",
    "grid_size = 100  # You can adjust this value\n",
    "x_points = np.linspace(min_x, max_x, grid_size)\n",
    "y_points = np.linspace(min_y, max_y, grid_size)\n",
    "\n",
    "# Round the points to 4 decimal places\n",
    "x_points = np.around(x_points, 4)\n",
    "y_points = np.around(y_points, 4)\n",
    "\n",
    "grid = [Point(x, y) for x in x_points for y in y_points]\n",
    "\n",
    "# drop the points that are not within the precincts\n",
    "def is_point_inside_precincts(point, precincts_gdf, idx):\n",
    "    for i in idx.intersection(point.bounds):\n",
    "        if point.within(precincts_gdf.iloc[i].geometry):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "filtered_grid = [point for point in grid if is_point_inside_precincts(point, precint_footprint, idx)]\n",
    "filtered_grid_df = pd.DataFrame([(point.x, point.y) for point in filtered_grid], columns=['Longitude', 'Latitude'])\n",
    "\n",
    "del grid \n",
    "del filtered_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate the basic spatial-temporal matrix\n",
    "For each point, crime probabbility will be analysed for each hour of the day and each day of the week."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def point_hour_day_combinations(points, hours, days_of_week):\n",
    "    for point, hour, day in itertools.product(points, hours, days_of_week):\n",
    "        yield point.x, point.y, hour, day\n",
    "\n",
    "# Convert filtered grid points to a list of Point objects\n",
    "points = [Point(lon, lat) for lon, lat in filtered_grid_df[['Longitude', 'Latitude']].values]\n",
    "\n",
    "# Define hours and days_of_week\n",
    "hours = range(24)\n",
    "days_of_week = range(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import the crime data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('..//data.pickle', 'rb') as f:\n",
    "    crime_data = pd.read_pickle(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Only keep the M and F sex values\n",
    "sexes = ['M', 'F']\n",
    "\n",
    "crime_data = crime_data.loc[crime_data['VIC_SEX'].isin(sexes)]\n",
    "# Re calculate the categories for the Sex column\n",
    "crime_data['VIC_SEX'] = crime_data['VIC_SEX'].cat.remove_unused_categories()\n",
    "\n",
    "del sexes\n",
    "crime_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# filter crime_data columns to only include the columns we need\n",
    "crime_data = crime_data[['CMPLNT_FR_DT', 'CMPLNT_FR_TM', 'Longitude','Latitude', 'VIC_SEX','VIC_AGE_GROUP']]\n",
    "crime_data.head(5)\n",
    "\n",
    "# get the day of the week and the hour of the day from the date and time columns\n",
    "crime_data['CMPLNT_FR_DT'] = pd.to_datetime(crime_data['CMPLNT_FR_DT'], format='%m/%d/%Y')\n",
    "crime_data['CMPLNT_FR_TM'] = pd.to_datetime(crime_data['CMPLNT_FR_TM'], format='%H:%M:%S')\n",
    "crime_data['day_of_week'] = crime_data['CMPLNT_FR_DT'].dt.dayofweek\n",
    "crime_data['hour'] = crime_data['CMPLNT_FR_TM'].dt.hour\n",
    "crime_data['year'] = crime_data['CMPLNT_FR_DT'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def nearest_grid_point(coord, grid_points):\n",
    "    nearest_index = np.argmin(np.abs(coord - grid_points))\n",
    "    return grid_points[nearest_index]\n",
    "\n",
    "# Find the nearest grid point for the longitude and latitude coordinates using the defined function\n",
    "crime_data['Longitude'] = crime_data['Longitude'].apply(nearest_grid_point, grid_points=x_points)\n",
    "crime_data['Latitude'] = crime_data['Latitude'].apply(nearest_grid_point, grid_points=y_points)\n",
    "\n",
    "\n",
    "crime_counts = (\n",
    "    crime_data.groupby(['Longitude', 'Latitude', 'day_of_week', 'hour', 'year', 'VIC_SEX'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    ")\n",
    "\n",
    "# Create a data frame with only data from 2022\n",
    "crime_counts_2022 = crime_counts.loc[crime_counts['year'] == 2022]\n",
    "\n",
    "# create a data frame all data except 2022\n",
    "crime_counts = crime_counts.loc[crime_counts['year'] != 2022]\n",
    "\n",
    "crime_datasets = [crime_counts, crime_counts_2022]\n",
    "\n",
    "# remove the year column from the data frames\n",
    "for crime_dataset in crime_datasets:\n",
    "    del crime_dataset['year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for crime_counts in crime_dataset:\n",
    "    crime_counts = pd.pivot_table(crime_counts, values='count', index=['Longitude', 'Latitude','hour', 'day_of_week'], columns=['VIC_SEX'], fill_value=0)\n",
    "    crime_counts = crime_counts.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trees"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Count the trees close to each grid point\n",
    "rows = None\n",
    "\n",
    "trees = gpd.read_file('../data/2015 Street Tree Census - Tree Data.geojson', rows=rows)\n",
    "trees = trees.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "trees['longitude'] = trees['longitude'].astype(float)\n",
    "trees['latitude'] = trees['latitude'].astype(float)\n",
    "\n",
    "trees['Longitude'] = trees['longitude'].apply(nearest_grid_point, grid_points=x_points)\n",
    "trees['Latitude'] = trees['latitude'].apply(nearest_grid_point, grid_points=y_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "trees.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tree_counts = (\n",
    "    trees.groupby(['Longitude', 'Latitude','health'])\n",
    "    .size()\n",
    "    .reset_index(name='tree_count')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tree_counts.head()\n",
    "\n",
    "tree_counts_pivoted = pd.pivot_table(tree_counts, values='tree_count', index=['Longitude', 'Latitude'], columns=['health'], fill_value=0)\n",
    "tree_counts_pivoted = tree_counts_pivoted.reset_index().rename(columns={'Good': 'good_tree_count', 'Fair': 'fair_tree_count', 'Poor': 'poor_tree_count'})\n",
    "\n",
    "# Remove index name\n",
    "tree_counts_pivoted.index.name = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "all_combinations = np.array(list(point_hour_day_combinations(points, hours, days_of_week)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Use the reindex method to index the matches directly\n",
    "for crime_counts in crime_dataset:\n",
    "    crime_counts.set_index(['Longitude', 'Latitude', 'hour', 'day_of_week'], inplace=True)\n",
    "    crime_counts = crime_counts.reindex(\n",
    "        pd.MultiIndex.from_arrays(all_combinations.T,\n",
    "        names=crime_counts.index.names),\n",
    "        fill_value=0\n",
    "        )\n",
    "    # Reset the index of the matched_data DataFrame\n",
    "    crime_counts.reset_index(inplace=True)\n",
    "    # Add the tree counts to the matched_df DataFrame\n",
    "    crime_counts = crime_counts.merge(tree_counts_pivoted, on=['Longitude', 'Latitude'], how='left').fillna(0)\n",
    "    crime_counts[['hour', 'day_of_week']] = crime_counts[['hour', 'day_of_week']].astype(int)\n",
    "    #Convert the tree count columns to int type\n",
    "    crime_counts[['good_tree_count', 'fair_tree_count', 'poor_tree_count']] = crime_counts[['good_tree_count', 'fair_tree_count', 'poor_tree_count']].astype(int)\n",
    "    # convert the F and M columns to int type\n",
    "    crime_counts[['F', 'M']] = crime_counts[['F', 'M']].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Final Export"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the matched_data DataFrame as a parquet file\n",
    "for crime_counts in crime_dataset:\n",
    "    crime_counts.to_parquet(f'../data/{str(crime_counts)}.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
