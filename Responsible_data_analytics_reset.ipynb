{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Modelling crime risk associated with Green Spaces\n",
    "---\n",
    "A case study of New York City using NYPD Complaint Data and Machine Learning models\n",
    "\n",
    "| Authors                        | Student ID   |\n",
    "|--------------------------------|--------------|\n",
    "| Kaninik Baradi                 | 5216664      |\n",
    "| Lala Sayyida Millati Nadhira   | 5844266      |\n",
    "| Rezzy Yolanda Wulandhari       | 4779487      |\n",
    "| Kelvin Engee                   | 4664043      |\n",
    "| Philippe Almeida Mirault       | 5898803      |\n",
    "Group 4\n",
    "\n",
    "For the course: Responsible Data Analytics, SEN 163B\n",
    "April 2023"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "This notebook is a companion to the report on Modelling Crime Risks associated with Green spaces. It contains all the code required to download, pre-process and analyse the data. The notebook is divided into the following sections:\n",
    "- Preparation\n",
    "- Descriptive Analytics\n",
    "    - Preliminary Analysis\n",
    "- Diagnostic Analytics\n",
    "    - Feature Analysis\n",
    "    - Feature Engineering\n",
    "    - Bias Analysis\n",
    "- Predictive Analysis\n",
    "    - Target Variable Analysis\n",
    "    - Train-Test Split Strategy\n",
    "    - Model Evaluation\n",
    "    - Model Interpretation\n",
    "- Prescriptive Analysis\n",
    "    - Cross Validation\n",
    "    - Ensemble Predictor\n",
    "    - Model Deployment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dependencies:\n",
    "\n",
    "Data Sources:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas\n",
    "import altair\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Descriptive Analytics\n",
    "This section contains the initial analysis of the selected data sets. It identifies the underlying relationships of the variables and if used to determine vriables of interest for further analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Complaints Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaninik\\AppData\\Local\\Temp\\ipykernel_35532\\2648708144.py:5: DtypeWarning: Columns (18,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  crime_data = pandas.read_csv(\"..\\\\NYPD_Complaint_Data_Historic.csv\", skiprows=lambda i: i>0 and every_third(i))\n"
     ]
    }
   ],
   "source": [
    "# Create a function that selects every third number\n",
    "def every_nth(n):\n",
    "    return n % 3 == 0\n",
    "\n",
    "crime_data = pandas.read_csv(\"..\\\\NYPD_Complaint_Data_Historic.csv\", skiprows=lambda i: i>0 and every_nth(i))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_categorical(dataframe, column):\n",
    "    # make the column of the dataframe categorical\n",
    "    dataframe[column] = dataframe[column].astype('category')\n",
    "\n",
    "# get a lst of all the columns in the dataframe that need to be categorical\n",
    "\n",
    "columns = ['ADDR_PCT_CD', 'BORO_NM', 'CRM_ATPT_CPTD_CD', 'HADEVELOPT', 'HOUSING_PSA', 'JURISDICTION_CODE', 'JURIS_DESC', 'KY_CD', 'LAW_CAT_CD', 'LOC_OF_OCCUR_DESC', 'OFNS_DESC', 'PARKS_NM', 'PATROL_BORO', 'PD_CD', 'PD_DESC', 'STATION_NAME', 'SUSP_RACE', 'SUSP_SEX', 'TRANSIT_DISTRICT', 'VIC_RACE', 'VIC_SEX']\n",
    "\n",
    "    # make each column categorical\n",
    "for column in columns:\n",
    "    make_categorical(crime_data, column)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(crime_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#scrub for duplicate\n",
    "crime_data.drop_duplicates(inplace=True)\n",
    "print(crime_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#scrub for irrelevant data (only use required columns)\n",
    "crime_data = crime_data[['CMPLNT_FR_DT','CMPLNT_FR_TM','Longitude','Latitude','VIC_SEX','VIC_RACE','VIC_AGE_GROUP']]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crime_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#unlike usual, all the rows with missing data is deleted beforehand, because there all the data is missing completely at random\n",
    "missing_counts = crime_data.isna().sum()\n",
    "\n",
    "print(missing_counts)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crime_data = crime_data.dropna(axis=0)\n",
    "\n",
    "print(crime_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#unlike usual, all the rows with missing data is deleted beforehand, because there all the data is missing completely at random\n",
    "missing_counts = crime_data.isna().sum()\n",
    "\n",
    "print(missing_counts)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CMPLNT_FR_DT\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crime_data[['month','day','year']] = crime_data['CMPLNT_FR_DT'].str.split('/',expand=True).astype(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crime_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crime_data = crime_data.loc[crime_data['year'] >= 2006]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crime_data['CMPLNT_FR_DT'] = pandas.to_datetime(crime_data['CMPLNT_FR_DT'], format='%m/%d/%Y')\n",
    "crime_data['day_of_week'] = crime_data['CMPLNT_FR_DT'].dt.dayofweek"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crime_data = crime_data.drop('CMPLNT_FR_DT', axis=1)\n",
    "crime_data = crime_data.drop('month', axis=1)\n",
    "crime_data = crime_data.drop('day', axis=1)\n",
    "crime_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CMPLNT_FR_TM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crime_data[['hour','minute','second']] = crime_data['CMPLNT_FR_TM'].str.split(':',expand=True).astype(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crime_data = crime_data.drop('CMPLNT_FR_TM', axis=1)\n",
    "crime_data = crime_data.drop('second', axis=1)\n",
    "crime_data = crime_data.drop('minute', axis=1)\n",
    "crime_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Grid the Longitude and Latitude"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a grid of points across the precincts to use as the center of the crime clusters\n",
    "# The size of the grid is n x n, where n is the number of points in each direction\n",
    "from shapely.geometry import Point, Polygon\n",
    "from rtree import index\n",
    "\n",
    "precint_footprint = gpd.read_file('..//data//Police Precincts.geojson')\n",
    "\n",
    "# get the bounds of the precincts\n",
    "min_x, min_y, max_x, max_y = precint_footprint.total_bounds\n",
    "\n",
    "idx = index.Index()\n",
    "for i, row in precint_footprint.iterrows():\n",
    "    idx.insert(i, row.geometry.bounds)\n",
    "\n",
    "grid_size = 100  # You can adjust this value\n",
    "x_points = np.linspace(min_x, max_x, grid_size)\n",
    "y_points = np.linspace(min_y, max_y, grid_size)\n",
    "\n",
    "# Round the points to 4 decimal places\n",
    "x_points = np.around(x_points, 5)\n",
    "y_points = np.around(y_points, 5)\n",
    "\n",
    "grid = [Point(x, y) for x in x_points for y in y_points]\n",
    "\n",
    "# drop the points that are not within the precincts\n",
    "def is_point_inside_precincts(point, precincts_gdf, idx):\n",
    "    for i in idx.intersection(point.bounds):\n",
    "        if point.within(precincts_gdf.iloc[i].geometry):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "filtered_grid = [point for point in grid if is_point_inside_precincts(point, precint_footprint, idx)]\n",
    "filtered_grid_df = pandas.DataFrame([(point.x, point.y) for point in filtered_grid], columns=['Longitude', 'Latitude'])\n",
    "#\n",
    "del grid\n",
    "del filtered_grid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# create a KD Tree with the Longitude and Latitude columns of filtered_grid_df\n",
    "kd_tree = cKDTree(filtered_grid_df[['Longitude', 'Latitude']])\n",
    "\n",
    "def nearest_grid_point(coord, grid_points):\n",
    "    nearest_index = np.argmin(np.abs(coord - grid_points))\n",
    "    return grid_points[nearest_index]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# query the KD Tree with the Longitude and Latitude columns of crime_data\n",
    "distances, indices = kd_tree.query(crime_data[['Longitude', 'Latitude']])\n",
    "\n",
    "# use the indices to get the corresponding Longitude and Latitude values from filtered_grid_df\n",
    "crime_data['Longitude'] = filtered_grid_df.loc[indices, 'Longitude'].values\n",
    "crime_data['Latitude'] = filtered_grid_df.loc[indices, 'Latitude'].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(crime_data['Longitude'], crime_data['Latitude'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crime_data = crime_data.loc[crime_data['Longitude'] > -74.5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crime_data = crime_data.loc[crime_data['Latitude'] < 42.5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crime_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# VIC_SEX"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crime_data['VIC_SEX'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Only keep the M and F sex values\n",
    "sexes = ['M', 'F']\n",
    "\n",
    "crime_data = crime_data.loc[crime_data['VIC_SEX'].isin(sexes)]\n",
    "# Re calculate the categories for the Sex column\n",
    "crime_data['VIC_SEX'] = crime_data['VIC_SEX'].cat.remove_unused_categories()\n",
    "\n",
    "del sexes\n",
    "crime_data.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crime_data['VIC_SEX'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# VIC_RACE\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crime_data['VIC_RACE'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Keep everything except for UNKNOWN and OTHER\n",
    "races = ['WHITE', 'WHITE HISPANIC', 'BLACK','ASIAN / PACIFIC ISLANDER', 'BLACK HISPANIC','AMERICAN INDIAN/ALASKAN NATIVE', 'OTHER']\n",
    "\n",
    "crime_data = crime_data.loc[crime_data['VIC_RACE'].isin(races)]\n",
    "# Re calculate the categories for the Sex column\n",
    "crime_data['VIC_RACE'] = crime_data['VIC_RACE'].cat.remove_unused_categories()\n",
    "\n",
    "del races\n",
    "crime_data.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crime_data['VIC_RACE'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# VIC_AGE_GROUP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crime_data['VIC_AGE_GROUP'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#remove values that don't belong to a victim age group\n",
    "crime_data['VIC_AGE_GROUP'] = numpy.where(crime_data['VIC_AGE_GROUP'].str.len()==4, None, crime_data['VIC_AGE_GROUP'])\n",
    "crime_data['VIC_AGE_GROUP'] = numpy.where(crime_data['VIC_AGE_GROUP'].str.startswith(\"-\"), None, crime_data['VIC_AGE_GROUP'])\n",
    "crime_data['VIC_AGE_GROUP'] = numpy.where(crime_data['VIC_AGE_GROUP'].str.contains(\"<\"), crime_data['VIC_AGE_GROUP'] + ' ', crime_data['VIC_AGE_GROUP'])\n",
    "crime_data['VIC_AGE_GROUP'] = numpy.where(crime_data['VIC_AGE_GROUP'].str.endswith(\"+\"), crime_data['VIC_AGE_GROUP'] + ' ', crime_data['VIC_AGE_GROUP'])\n",
    "crime_data['VIC_AGE_GROUP'] = numpy.where(crime_data['VIC_AGE_GROUP'].str.contains(\"UNKNOWN\"), None, crime_data['VIC_AGE_GROUP'])\n",
    "crime_data['VIC_AGE_GROUP'] = numpy.where(crime_data['VIC_AGE_GROUP'].str.len()==3, None, crime_data['VIC_AGE_GROUP'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crime_data.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#delete None\n",
    "crime_data = crime_data.dropna(subset=['VIC_AGE_GROUP'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crime_data['VIC_AGE_GROUP'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crime_data.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# One hot encoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "one_hot_encoded = pandas.get_dummies(crime_data[['VIC_SEX','VIC_RACE','VIC_AGE_GROUP']])\n",
    "one_hot_encoded"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "one_hot_encoded_df = crime_data\n",
    "\n",
    "# concatenate the one-hot encoded columns with the original dataframe\n",
    "one_hot_encoded_df = pandas.concat([one_hot_encoded_df, one_hot_encoded], axis=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "one_hot_encoded_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# drop the VIC_SEX, VIC_Race, and VIC_AGE_GROUP columns\n",
    "one_hot_encoded_df = one_hot_encoded_df.drop('VIC_SEX', axis=1)\n",
    "one_hot_encoded_df = one_hot_encoded_df.drop('VIC_RACE', axis=1)\n",
    "one_hot_encoded_df = one_hot_encoded_df.drop('VIC_AGE_GROUP', axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crime_counts = (\n",
    "    one_hot_encoded_df.groupby(['Longitude', 'Latitude', 'year', 'day_of_week', 'hour'])\n",
    "    .sum()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crime_counts.reset_index(inplace=True)\n",
    "crime_counts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Trees"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rows = None\n",
    "\n",
    "trees = gpd.read_file('../data/2015 Street Tree Census - Tree Data.geojson', rows=rows)\n",
    "# trees = trees.to_crs(epsg=4326)\n",
    "trees"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# drop the columns that we don't need\n",
    "trees = trees[['health', 'longitude', 'latitude']]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# query the KD Tree with the Longitude and Latitude columns of crime_data\n",
    "distances, indices = kd_tree.query(trees[['longitude', 'latitude']])\n",
    "\n",
    "# use the indices to get the corresponding Longitude and Latitude values from filtered_grid_df\n",
    "trees['Longitude'] = filtered_grid_df.loc[indices, 'Longitude'].values\n",
    "trees['Latitude'] = filtered_grid_df.loc[indices, 'Latitude'].values\n",
    "\n",
    "tree_counts = (\n",
    "    trees.groupby(['Longitude', 'Latitude','health'])\n",
    "    .size()\n",
    "    .reset_index(name='tree_count')\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tree_counts.head()\n",
    "\n",
    "tree_counts_pivoted = pandas.pivot_table(tree_counts, values='tree_count', index=['Longitude', 'Latitude'], columns=['health'], fill_value=0)\n",
    "tree_counts_pivoted = tree_counts_pivoted.reset_index().rename(columns={'Good': 'good_tree_count', 'Fair': 'fair_tree_count', 'Poor': 'poor_tree_count'})\n",
    "\n",
    "# Remove index name\n",
    "tree_counts_pivoted.index.name = None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tree_counts_pivoted"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Creation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def point_hour_day_combinations(points, hours, days_of_week, years)\n",
    "    for point, hour, day in itertools.product(points, hours, days_of_week, years):\n",
    "        yield point.x, point.y, hour, day, years\n",
    "\n",
    "# Convert filtered grid points to a list of Point objects\n",
    "points = [Point(lon, lat) for lon, lat in filtered_grid_df[['Longitude', 'Latitude']].values]\n",
    "\n",
    "# Define hours and days_of_week\n",
    "hours = range(24)\n",
    "days_of_week = range(7)\n",
    "years = range(2006, 2021)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_combinations = np.array(list(point_hour_day_combinations(points, hours, days_of_week)))\n",
    "crime_counts.set_index(['Longitude', 'Latitude', 'year', 'day_of_week', 'hour'], inplace=True)\n",
    "matched_data = crime_counts.reindex(\n",
    "    pd.MultiIndex.from_arrays(all_combinations.T, names=crime_counts.index.names),\n",
    "    fill_value=0\n",
    ")\n",
    "matched_data = matched_data.merge(tree_counts_pivoted, on=['Longitude', 'Latitude'], how='left').fillna(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "matched_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('merged_data.pickle', 'wb') as f:\n",
    "    pickle.dump(matched_data, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LAB 4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Proxies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corr_matrix = matched_data.corr().round(2)\n",
    "# print(corr_matrix)\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(40,40))       \n",
    "sns.heatmap(corr_matrix, annot=True, vmax=1, vmin=-1, center=0, cmap='vlag', mask=mask, ax=ax)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Representation bias"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('merged_data.pickle', 'rb') as f:\n",
    "    matched_data = pickle.load(f, encoding='binary')\n",
    "matched_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_data2010 = matched_data.loc[matched_data['year'] == 2010]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_data2010"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "total_male = merged_data2010['VIC_SEX_M'].sum()\n",
    "total_female = merged_data2010['VIC_SEX_F'].sum()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = ['F', 'M']  # categories\n",
    "y = [total_female, total_male]  # values\n",
    "bin_edges = range(len(x) + 1)  # define bin edges\n",
    "\n",
    "plt.bar(x, y)\n",
    "plt.xticks(range(len(x)), x)\n",
    "plt.xlabel('Sex of victims')\n",
    "plt.ylabel('Number of victims')\n",
    "plt.title('Sex distribution of victims')\n",
    "plt.plot(range(len(x)), [167849, 151816], 'o--', c='red', linewidth=0, markersize=8, label='Expected sex distribution according to New York Census 2010')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "total_18 = merged_data2010.iloc[:, 17].sum()\n",
    "total_24 = merged_data2010['VIC_AGE_GROUP_18-24'].sum()\n",
    "total_44 = merged_data2010['VIC_AGE_GROUP_25-44'].sum()\n",
    "total_64 = merged_data2010['VIC_AGE_GROUP_45-64'].sum()\n",
    "total_65 = merged_data2010.iloc[:, 16].sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = ['<18', '18-24', '25-44', '45-64', '65+']\n",
    "y = [total_18, total_24, total_44, total_64, total_65]\n",
    "\n",
    "bin_edges = np.arange(len(x) + 1) - 0.5  # add a half bin width to shift the edges to the center of the bars\n",
    "bin_edges = range(len(x) + 1)  # define bin edges\n",
    "\n",
    "plt.bar(x, y)\n",
    "plt.xticks(range(len(x)), x)\n",
    "plt.xlabel('Age group of victims')\n",
    "plt.ylabel('Number of victims')\n",
    "plt.title('Age group distribution of victims')\n",
    "plt.plot(range(len(x)), [69137, 33993, 99598, 78102, 38835], 'o--', c='red', linewidth=0, markersize=8, label='Expected age distribution according to New York Census 2010')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "white_hispanic = merged_data2010['VIC_RACE_WHITE HISPANIC'].sum()\n",
    "black = merged_data2010['VIC_RACE_BLACK'].sum()\n",
    "white = merged_data2010['VIC_RACE_WHITE'].sum()\n",
    "black_hispanic = merged_data2010['VIC_RACE_BLACK HISPANIC'].sum()\n",
    "asian_pacific = merged_data2010['VIC_RACE_ASIAN / PACIFIC ISLANDER'].sum()\n",
    "american_alaskan = merged_data2010['VIC_RACE_AMERICAN INDIAN/ALASKAN NATIVE'].sum()\n",
    "other = merged_data2010['VIC_RACE_OTHER'].sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = ['WH','B','W','BH','A/P','A/A', 'Other']\n",
    "y = [white_hispanic, black, white, black_hispanic, asian_pacific, american_alaskan, other]\n",
    "\n",
    "bin_edges = np.arange(len(x) + 1) - 0.5  # add a half bin width to shift the edges to the center of the bars\n",
    "bin_edges = range(len(x) + 1)  # define bin edges\n",
    "\n",
    "plt.bar(x, y)\n",
    "plt.xticks(range(len(x)), x)\n",
    "plt.xlabel('Race group of victims')\n",
    "plt.ylabel('Number of victims')\n",
    "plt.title('Race group distribution of victims')\n",
    "plt.plot(range(len(x)), [45673 , 72781, 106471, 45673, 40311, 681 ,2262], 'o--', c='red', linewidth=0, markersize=8, label='Expected race distribution according to New York Census 2010')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Historical bias"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "non_victim_male = 3882544 - merged_data2010['VIC_SEX_M'].sum()\n",
    "non_victim_female = 4292589 - merged_data2010['VIC_SEX_F'].sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Define the data and log scale it\n",
    "victims = [total_male, total_female]\n",
    "non_victims = [non_victim_male, non_victim_female]\n",
    "\n",
    "labels = ['male', 'female']\n",
    "colors = ['orange', 'blue']\n",
    "\n",
    "# Create the stacked bar plot\n",
    "x = np.arange(len(labels))\n",
    "plt.bar(x, victims, color=colors[0], label='victims')\n",
    "plt.bar(x, non_victims, bottom=victims, color=colors[1], label='non_victims')\n",
    "plt.xticks(x, labels)\n",
    "plt.ylabel('Value')\n",
    "plt.title('Stacked Bar Plot with Two Numbers')\n",
    "plt.legend()\n",
    "\n",
    "# Set y-axis to log scale and adjust limits\n",
    "plt.yscale('log')\n",
    "plt.ylim([1, 10**7])\n",
    "\n",
    "# Set y-axis tick labels to display original scale values\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "non_victim_male"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "non_victim_18 = 1768111 - merged_data2010.iloc[:, 17].sum()\n",
    "non_victim_24 = merged_data2010['VIC_AGE_GROUP_18-24'].sum()\n",
    "non_victim_44 = merged_data2010['VIC_AGE_GROUP_25-44'].sum()\n",
    "non_victim_64 = merged_data2010['VIC_AGE_GROUP_45-64'].sum()\n",
    "non_victim_65 = merged_data2010.iloc[:, 16].sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predictive Analytics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
